{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "KjYmCKn_IqVb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76a7b403e38666632f402b840d226217",
     "grade": false,
     "grade_id": "intro-chal-02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# A Bit Of Data Science\n",
    "\n",
    "Before you start solving the challenge, press `Ctrl-Enter` (PC) or `Command-Enter` (Mac) in the cell below. It will load the modules needed for testing and auto-grading the challenges. After you did, a number between the square brackets will appear in front of the cell, like - for example:\n",
    "```python\n",
    "[1]\n",
    "```\n",
    "If successful, the following message will appear below the first cell:\n",
    "```python\n",
    "Assertions imported OK\n",
    "Test cells imported OK\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "h8x4OStuDkXJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a082795941dfe74c9cacc4d167fb3fc",
     "grade": false,
     "grade_id": "import-chal-02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell first!\n",
    "\n",
    "import httpimport\n",
    "with httpimport.github_repo('eur-nl', 'assertions'):\n",
    "    from assertions import *\n",
    "with httpimport.github_repo('jjengelberts', 'precourse-test'):\n",
    "    from test_cells import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00f2f7e7142914f2096fc660e6ad8b82",
     "grade": false,
     "grade_id": "spacer-chal-02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f22e138f58eaa136fe95bdb02421100",
     "grade": false,
     "grade_id": "explain-chal-02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Challenge 2b\n",
    "\n",
    "As a Data Scientist, it is quite common to encounter \"dirty\" data. For example, you might have a table with a column that should contain numbers, except some cells contain something else.\n",
    "\n",
    "In this challenge your function `challenge_2b(raw_data)` takes a list corresponding to a column of data where some of the cells contain the word `Missing` (see the example).\n",
    "\n",
    "Finalize `challenge_3b(raw_data)` in such a way that it calculates the average of the numbers present in the list, while excluding the `Missing` values.\n",
    "\n",
    "**TIP** You can do this in multiple ways! Make use of indexing or a for loop. If you are able, try to apply a [pythonic way](https://realpython.com/lessons/pythonic-loops-overview/) to solve this.\n",
    "\n",
    "## Example input\n",
    "```python\n",
    "[1.0, 2.0, 'Missing', 4.0, 5.0, 'Missing', 'Missing', 8.0, 'Missing', 10.0]\n",
    "```\n",
    "\n",
    "## Example return value\n",
    "```python\n",
    "5.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caa6465c80063d633b7ccd1ce55ac8db",
     "grade": false,
     "grade_id": "code-chal-02b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code cell\n",
    "\n",
    "def challenge_2b(raw_data):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84fd065555fa766f1934617f9cf424d0",
     "grade": false,
     "grade_id": "test-chal-02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "test_challenge_2b(challenge_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "260443c336b168e0739b525b33f8fe01",
     "grade": true,
     "grade_id": "assert-chal-02b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assertion cell\n",
    "\n",
    "check_assertion(challenge_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e037890058bc993e4362d635b021c381",
     "grade": false,
     "grade_id": "next-chal-02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Next challenge\n",
    "\n",
    "Great job! If you solved this challenge, you are ready for **Challenge 3b**:\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jjengelberts/precourse-test/blob/main/Challenge3b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Challenge 3b\"/></a>\n",
    "\n",
    "If you were not able to complete the challenge above, you can practice your skills a bit more by  **Challenge 3c**:\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jjengelberts/precourse-test/blob/main/Challenge3c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Challenge 3c\"/></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUEcdmwI2GVB9qr8nWeY6I",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
